{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: gym_super_mario_bros==7.3.0 in c:\\users\\ithompson\\rl\\lib\\site-packages (7.3.0)\n",
      "Requirement already satisfied: nes_py in c:\\users\\ithompson\\rl\\lib\\site-packages (8.2.1)\n",
      "Requirement already satisfied: gym>=0.17.2 in c:\\users\\ithompson\\rl\\lib\\site-packages (from nes_py) (0.26.2)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\ithompson\\rl\\lib\\site-packages (from nes_py) (1.26.4)\n",
      "Requirement already satisfied: pyglet<=1.5.21,>=1.4.0 in c:\\users\\ithompson\\rl\\lib\\site-packages (from nes_py) (1.5.21)\n",
      "Requirement already satisfied: tqdm>=4.48.2 in c:\\users\\ithompson\\rl\\lib\\site-packages (from nes_py) (4.66.4)\n",
      "Requirement already satisfied: cloudpickle>=1.2.0 in c:\\users\\ithompson\\rl\\lib\\site-packages (from gym>=0.17.2->nes_py) (3.0.0)\n",
      "Requirement already satisfied: gym-notices>=0.0.4 in c:\\users\\ithompson\\rl\\lib\\site-packages (from gym>=0.17.2->nes_py) (0.0.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\ithompson\\rl\\lib\\site-packages (from tqdm>=4.48.2->nes_py) (0.4.6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install gym_super_mario_bros==7.3.0 nes_py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the game\n",
    "import gym_super_mario_bros\n",
    "# Import the Joypad wrapper\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "# Import the SIMPLIFIED controls\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup game\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v3')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ithompson\\rl\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:195: UserWarning: \u001b[33mWARN: The result returned by `env.reset()` was not a tuple of the form `(obs, info)`, where `obs` is a observation and `info` is a dictionary containing additional information. Actual type: `<class 'numpy.ndarray'>`\u001b[0m\n",
      "  logger.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[104, 136, 252],\n",
       "        [104, 136, 252],\n",
       "        [104, 136, 252],\n",
       "        ...,\n",
       "        [104, 136, 252],\n",
       "        [104, 136, 252],\n",
       "        [104, 136, 252]],\n",
       "\n",
       "       [[104, 136, 252],\n",
       "        [104, 136, 252],\n",
       "        [104, 136, 252],\n",
       "        ...,\n",
       "        [104, 136, 252],\n",
       "        [104, 136, 252],\n",
       "        [104, 136, 252]],\n",
       "\n",
       "       [[104, 136, 252],\n",
       "        [104, 136, 252],\n",
       "        [104, 136, 252],\n",
       "        ...,\n",
       "        [104, 136, 252],\n",
       "        [104, 136, 252],\n",
       "        [104, 136, 252]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[228,  92,  16],\n",
       "        [228,  92,  16],\n",
       "        [228,  92,  16],\n",
       "        ...,\n",
       "        [228,  92,  16],\n",
       "        [228,  92,  16],\n",
       "        [228,  92,  16]],\n",
       "\n",
       "       [[228,  92,  16],\n",
       "        [228,  92,  16],\n",
       "        [228,  92,  16],\n",
       "        ...,\n",
       "        [228,  92,  16],\n",
       "        [228,  92,  16],\n",
       "        [228,  92,  16]],\n",
       "\n",
       "       [[228,  92,  16],\n",
       "        [228,  92,  16],\n",
       "        [228,  92,  16],\n",
       "        ...,\n",
       "        [228,  92,  16],\n",
       "        [228,  92,  16],\n",
       "        [228,  92,  16]]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ithompson\\rl\\Lib\\site-packages\\gym\\envs\\registration.py:555: UserWarning: \u001b[33mWARN: The environment SuperMarioBros-v0 is out of date. You should consider upgrading to version `v3`.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\ithompson\\rl\\Lib\\site-packages\\gym\\envs\\registration.py:627: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
      "  logger.warn(\n"
     ]
    }
   ],
   "source": [
    "env = gym_super_mario_bros.make('SuperMarioBros-v0', apply_api_compatibility=True, render_mode=\"human\")\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ithompson\\rl\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n",
      "c:\\Users\\ithompson\\rl\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:272: UserWarning: \u001b[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\ithompson\\rl\\Lib\\site-packages\\gym_super_mario_bros\\smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    }
   ],
   "source": [
    "# Create a flag - restart or not\n",
    "done = True\n",
    "# Loop through each frame in the game\n",
    "for step in range(1000):\n",
    "# Start the game to begin with\n",
    "    if done:\n",
    "        env.reset()\n",
    "    observation, reward, terminated, truncated, info = env.step(env.action_space.sample())\n",
    "    done = terminated or truncated\n",
    "    env.render()\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://download.pytorch.org/whl/cu124\n",
      "Requirement already satisfied: torch in c:\\users\\ithompson\\rl\\lib\\site-packages (2.4.0+cu118)\n",
      "Requirement already satisfied: torchvision in c:\\users\\ithompson\\rl\\lib\\site-packages (0.19.0+cu118)\n",
      "Requirement already satisfied: torchaudio in c:\\users\\ithompson\\rl\\lib\\site-packages (2.4.0+cu118)\n",
      "Requirement already satisfied: filelock in c:\\users\\ithompson\\rl\\lib\\site-packages (from torch) (3.15.4)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ithompson\\rl\\lib\\site-packages (from torch) (4.12.2)\n",
      "Requirement already satisfied: sympy in c:\\users\\ithompson\\rl\\lib\\site-packages (from torch) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ithompson\\rl\\lib\\site-packages (from torch) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ithompson\\rl\\lib\\site-packages (from torch) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ithompson\\rl\\lib\\site-packages (from torch) (2024.6.1)\n",
      "Requirement already satisfied: numpy in c:\\users\\ithompson\\rl\\lib\\site-packages (from torchvision) (1.26.4)\n",
      "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in c:\\users\\ithompson\\rl\\lib\\site-packages (from torchvision) (10.4.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ithompson\\rl\\lib\\site-packages (from jinja2->torch) (2.1.5)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ithompson\\rl\\lib\\site-packages (from sympy->torch) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install pytorch\n",
    "#old version\n",
    "# !pip install torch==1.10.1+cu113 torchvision==0.11.2+cu113 torchaudio===0.10.1+cu113 -f https://download.pytorch.org/whl/cu113/torch_stable.html\n",
    "\n",
    "#new version\n",
    "!pip3 install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu124"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: stable-baselines3[extra] in c:\\users\\ithompson\\rl\\lib\\site-packages (2.3.2)\n",
      "Requirement already satisfied: gymnasium<0.30,>=0.28.1 in c:\\users\\ithompson\\rl\\lib\\site-packages (from stable-baselines3[extra]) (0.29.1)\n",
      "Requirement already satisfied: numpy>=1.20 in c:\\users\\ithompson\\rl\\lib\\site-packages (from stable-baselines3[extra]) (1.26.4)\n",
      "Requirement already satisfied: torch>=1.13 in c:\\users\\ithompson\\rl\\lib\\site-packages (from stable-baselines3[extra]) (2.4.0+cu118)\n",
      "Requirement already satisfied: cloudpickle in c:\\users\\ithompson\\rl\\lib\\site-packages (from stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pandas in c:\\users\\ithompson\\rl\\lib\\site-packages (from stable-baselines3[extra]) (2.2.2)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ithompson\\rl\\lib\\site-packages (from stable-baselines3[extra]) (3.9.0)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\ithompson\\rl\\lib\\site-packages (from stable-baselines3[extra]) (4.10.0.84)\n",
      "Requirement already satisfied: pygame in c:\\users\\ithompson\\rl\\lib\\site-packages (from stable-baselines3[extra]) (2.6.0)\n",
      "Requirement already satisfied: tensorboard>=2.9.1 in c:\\users\\ithompson\\rl\\lib\\site-packages (from stable-baselines3[extra]) (2.17.0)\n",
      "Requirement already satisfied: psutil in c:\\users\\ithompson\\rl\\lib\\site-packages (from stable-baselines3[extra]) (6.0.0)\n",
      "Requirement already satisfied: tqdm in c:\\users\\ithompson\\rl\\lib\\site-packages (from stable-baselines3[extra]) (4.66.4)\n",
      "Requirement already satisfied: rich in c:\\users\\ithompson\\rl\\lib\\site-packages (from stable-baselines3[extra]) (13.7.1)\n",
      "Requirement already satisfied: shimmy~=1.3.0 in c:\\users\\ithompson\\rl\\lib\\site-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]) (1.3.0)\n",
      "Requirement already satisfied: pillow in c:\\users\\ithompson\\rl\\lib\\site-packages (from stable-baselines3[extra]) (10.4.0)\n",
      "Requirement already satisfied: autorom~=0.6.1 in c:\\users\\ithompson\\rl\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: click in c:\\users\\ithompson\\rl\\lib\\site-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (8.1.7)\n",
      "Requirement already satisfied: requests in c:\\users\\ithompson\\rl\\lib\\site-packages (from autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.32.3)\n",
      "Requirement already satisfied: AutoROM.accept-rom-license in c:\\users\\ithompson\\rl\\lib\\site-packages (from autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (0.6.1)\n",
      "Requirement already satisfied: typing-extensions>=4.3.0 in c:\\users\\ithompson\\rl\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (4.12.2)\n",
      "Requirement already satisfied: farama-notifications>=0.0.1 in c:\\users\\ithompson\\rl\\lib\\site-packages (from gymnasium<0.30,>=0.28.1->stable-baselines3[extra]) (0.0.4)\n",
      "Requirement already satisfied: ale-py~=0.8.1 in c:\\users\\ithompson\\rl\\lib\\site-packages (from shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]) (0.8.1)\n",
      "Requirement already satisfied: absl-py>=0.4 in c:\\users\\ithompson\\rl\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.0)\n",
      "Requirement already satisfied: grpcio>=1.48.2 in c:\\users\\ithompson\\rl\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.65.4)\n",
      "Requirement already satisfied: markdown>=2.6.8 in c:\\users\\ithompson\\rl\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.6)\n",
      "Requirement already satisfied: protobuf!=4.24.0,<5.0.0,>=3.19.6 in c:\\users\\ithompson\\rl\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (4.25.4)\n",
      "Requirement already satisfied: setuptools>=41.0.0 in c:\\users\\ithompson\\rl\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (65.5.0)\n",
      "Requirement already satisfied: six>1.9 in c:\\users\\ithompson\\rl\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (1.16.0)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in c:\\users\\ithompson\\rl\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in c:\\users\\ithompson\\rl\\lib\\site-packages (from tensorboard>=2.9.1->stable-baselines3[extra]) (3.0.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\ithompson\\rl\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.15.4)\n",
      "Requirement already satisfied: sympy in c:\\users\\ithompson\\rl\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (1.13.1)\n",
      "Requirement already satisfied: networkx in c:\\users\\ithompson\\rl\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.3)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ithompson\\rl\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (3.1.4)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ithompson\\rl\\lib\\site-packages (from torch>=1.13->stable-baselines3[extra]) (2024.6.1)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ithompson\\rl\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.2.1)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\users\\ithompson\\rl\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ithompson\\rl\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (4.53.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ithompson\\rl\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ithompson\\rl\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (24.1)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ithompson\\rl\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (3.1.2)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\users\\ithompson\\rl\\lib\\site-packages (from matplotlib->stable-baselines3[extra]) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ithompson\\rl\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ithompson\\rl\\lib\\site-packages (from pandas->stable-baselines3[extra]) (2024.1)\n",
      "Requirement already satisfied: markdown-it-py>=2.2.0 in c:\\users\\ithompson\\rl\\lib\\site-packages (from rich->stable-baselines3[extra]) (3.0.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in c:\\users\\ithompson\\rl\\lib\\site-packages (from rich->stable-baselines3[extra]) (2.18.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ithompson\\rl\\lib\\site-packages (from tqdm->stable-baselines3[extra]) (0.4.6)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\ithompson\\rl\\lib\\site-packages (from ale-py~=0.8.1->shimmy[atari]~=1.3.0; extra == \"extra\"->stable-baselines3[extra]) (6.4.0)\n",
      "Requirement already satisfied: mdurl~=0.1 in c:\\users\\ithompson\\rl\\lib\\site-packages (from markdown-it-py>=2.2.0->rich->stable-baselines3[extra]) (0.1.2)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in c:\\users\\ithompson\\rl\\lib\\site-packages (from werkzeug>=1.0.1->tensorboard>=2.9.1->stable-baselines3[extra]) (2.1.5)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ithompson\\rl\\lib\\site-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\ithompson\\rl\\lib\\site-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\ithompson\\rl\\lib\\site-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ithompson\\rl\\lib\\site-packages (from requests->autorom~=0.6.1->autorom[accept-rom-license]~=0.6.1; extra == \"extra\"->stable-baselines3[extra]) (2024.7.4)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ithompson\\rl\\lib\\site-packages (from sympy->torch>=1.13->stable-baselines3[extra]) (1.3.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# Install stable baselines for RL stuff\n",
    "!pip install stable-baselines3[extra]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Frame Stacker Wrapper and GrayScaling Wrapper\n",
    "from gym.wrappers import GrayScaleObservation\n",
    "# Import Vectorization Wrappers\n",
    "from stable_baselines3.common.vec_env import VecFrameStack, DummyVecEnv\n",
    "# Import Matplotlib to show the impact of frame stacking\n",
    "from matplotlib import pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ithompson\\rl\\Lib\\site-packages\\gym\\envs\\registration.py:627: UserWarning: \u001b[33mWARN: The environment creator metadata doesn't include `render_modes`, contains: ['render.modes', 'video.frames_per_second']\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\ithompson\\rl\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\patch_gym.py:49: UserWarning: You provided an OpenAI Gym environment. We strongly recommend transitioning to Gymnasium environments. Stable-Baselines3 is automatically wrapping your environments in a compatibility layer, which could potentially cause issues.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# 1. Create the base environment\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-v3', apply_api_compatibility=True, render_mode=\"human\")\n",
    "# 2. Simplify the controls \n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "# 3. Grayscale\n",
    "env = GrayScaleObservation(env, keep_dim=True)\n",
    "# 4. Wrap inside the Dummy Environment\n",
    "env = DummyVecEnv([lambda: env])\n",
    "# 5. Stack the frames\n",
    "env = VecFrameStack(env, 4, channels_order='last')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['NOOP'],\n",
       " ['right'],\n",
       " ['right', 'A'],\n",
       " ['right', 'B'],\n",
       " ['right', 'A', 'B'],\n",
       " ['A'],\n",
       " ['left']]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SIMPLE_MOVEMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "JoypadSpace.reset = lambda self, **kwargs: self.env.reset(**kwargs)\n",
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ithompson\\rl\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:233: DeprecationWarning: `np.bool8` is a deprecated alias for `np.bool_`.  (Deprecated NumPy 1.24)\n",
      "  if not isinstance(terminated, (bool, np.bool8)):\n"
     ]
    }
   ],
   "source": [
    "for i in range(55):\n",
    "    state, reward, done, info = env.step([4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,16))\n",
    "for idx in range(state.shape[3]):\n",
    "    plt.subplot(1,4,idx+1)\n",
    "    plt.imshow(state[0][:,:,idx])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we actually start training the model on the environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import os for file path management\n",
    "import os \n",
    "# Import PPO for algos\n",
    "from stable_baselines3 import PPO\n",
    "# Import Base Callback for saving models\n",
    "from stable_baselines3.common.callbacks import BaseCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TrainAndLoggingCallback(BaseCallback):\n",
    "\n",
    "    def __init__(self, check_freq, save_path, verbose=1):\n",
    "        super(TrainAndLoggingCallback, self).__init__(verbose)\n",
    "        self.check_freq = check_freq\n",
    "        self.save_path = save_path\n",
    "\n",
    "    def _init_callback(self):\n",
    "        if self.save_path is not None:\n",
    "            os.makedirs(self.save_path, exist_ok=True)\n",
    "\n",
    "    def _on_step(self):\n",
    "        if self.n_calls % self.check_freq == 0:\n",
    "            model_path = os.path.join(self.save_path, 'best_model_{}'.format(self.n_calls))\n",
    "            self.model.save(model_path)\n",
    "\n",
    "        return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_DIR = 'C:/Users/ithompson/ml_train/python scripts/models/mario_ppo/bestmodel'\n",
    "LOG_DIR = 'C:/Users/ithompson/ml_train/python scripts/models/mario_ppo/tensorboard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup model saving callback\n",
    "callback = TrainAndLoggingCallback(check_freq=10000, save_path=CHECKPOINT_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import torch\n",
    "# torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cuda\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "print(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "LOG_DIR = \"C://Users//ithompson//rl//mario_logdir\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n",
      "Wrapping the env in a VecTransposeImage.\n"
     ]
    }
   ],
   "source": [
    "# This is the AI model started\n",
    "model = PPO('CnnPolicy', env, verbose=1, tensorboard_log=LOG_DIR, learning_rate=0.000001, n_steps=512) #steps indicates how long before the model is updated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "UsageError: Line magic function `%tensorboard` not found.\n"
     ]
    }
   ],
   "source": [
    "!tensorboard --logdir {LOG_DIR}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logging to C://Users//ithompson//rl//mario_logdir\\PPO_3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ithompson\\rl\\Lib\\site-packages\\gym_super_mario_bros\\smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------\n",
      "| time/              |     |\n",
      "|    fps             | 55  |\n",
      "|    iterations      | 1   |\n",
      "|    time_elapsed    | 9   |\n",
      "|    total_timesteps | 512 |\n",
      "----------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 60            |\n",
      "|    iterations           | 2             |\n",
      "|    time_elapsed         | 17            |\n",
      "|    total_timesteps      | 1024          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.9818773e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | 0.00273       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 150           |\n",
      "|    n_updates            | 10            |\n",
      "|    policy_gradient_loss | 1.36e-05      |\n",
      "|    value_loss           | 375           |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 60            |\n",
      "|    iterations           | 3             |\n",
      "|    time_elapsed         | 25            |\n",
      "|    total_timesteps      | 1536          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.1657517e-05 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | -0.0209       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0856        |\n",
      "|    n_updates            | 20            |\n",
      "|    policy_gradient_loss | -0.000608     |\n",
      "|    value_loss           | 0.945         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 61            |\n",
      "|    iterations           | 4             |\n",
      "|    time_elapsed         | 33            |\n",
      "|    total_timesteps      | 2048          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 2.6635826e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | 0.00426       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.124         |\n",
      "|    n_updates            | 30            |\n",
      "|    policy_gradient_loss | -5.62e-05     |\n",
      "|    value_loss           | 0.518         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 61            |\n",
      "|    iterations           | 5             |\n",
      "|    time_elapsed         | 41            |\n",
      "|    total_timesteps      | 2560          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 9.1653783e-07 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | 0.00263       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0837        |\n",
      "|    n_updates            | 40            |\n",
      "|    policy_gradient_loss | -1.12e-05     |\n",
      "|    value_loss           | 0.378         |\n",
      "-------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 61            |\n",
      "|    iterations           | 6             |\n",
      "|    time_elapsed         | 49            |\n",
      "|    total_timesteps      | 3072          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 4.2355387e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | -0.0105       |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.191         |\n",
      "|    n_updates            | 50            |\n",
      "|    policy_gradient_loss | -9.9e-05      |\n",
      "|    value_loss           | 0.427         |\n",
      "-------------------------------------------\n",
      "-----------------------------------------\n",
      "| time/                   |             |\n",
      "|    fps                  | 55          |\n",
      "|    iterations           | 7           |\n",
      "|    time_elapsed         | 65          |\n",
      "|    total_timesteps      | 3584        |\n",
      "| train/                  |             |\n",
      "|    approx_kl            | 4.11144e-06 |\n",
      "|    clip_fraction        | 0           |\n",
      "|    clip_range           | 0.2         |\n",
      "|    entropy_loss         | -1.95       |\n",
      "|    explained_variance   | -0.00887    |\n",
      "|    learning_rate        | 1e-06       |\n",
      "|    loss                 | 0.0827      |\n",
      "|    n_updates            | 60          |\n",
      "|    policy_gradient_loss | -8.86e-05   |\n",
      "|    value_loss           | 0.232       |\n",
      "-----------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 50           |\n",
      "|    iterations           | 8            |\n",
      "|    time_elapsed         | 81           |\n",
      "|    total_timesteps      | 4096         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 2.640183e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.00367      |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0597       |\n",
      "|    n_updates            | 70           |\n",
      "|    policy_gradient_loss | -6.57e-05    |\n",
      "|    value_loss           | 0.177        |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 47           |\n",
      "|    iterations           | 9            |\n",
      "|    time_elapsed         | 96           |\n",
      "|    total_timesteps      | 4608         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.415881e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.00864      |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 45           |\n",
      "|    n_updates            | 80           |\n",
      "|    policy_gradient_loss | -3.07e-05    |\n",
      "|    value_loss           | 58.4         |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 48           |\n",
      "|    iterations           | 10           |\n",
      "|    time_elapsed         | 105          |\n",
      "|    total_timesteps      | 5120         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 4.324247e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | 0.0247       |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.104        |\n",
      "|    n_updates            | 90           |\n",
      "|    policy_gradient_loss | -7.12e-05    |\n",
      "|    value_loss           | 0.4          |\n",
      "------------------------------------------\n",
      "------------------------------------------\n",
      "| time/                   |              |\n",
      "|    fps                  | 46           |\n",
      "|    iterations           | 11           |\n",
      "|    time_elapsed         | 120          |\n",
      "|    total_timesteps      | 5632         |\n",
      "| train/                  |              |\n",
      "|    approx_kl            | 6.857328e-06 |\n",
      "|    clip_fraction        | 0            |\n",
      "|    clip_range           | 0.2          |\n",
      "|    entropy_loss         | -1.95        |\n",
      "|    explained_variance   | -0.0293      |\n",
      "|    learning_rate        | 1e-06        |\n",
      "|    loss                 | 0.0919       |\n",
      "|    n_updates            | 100          |\n",
      "|    policy_gradient_loss | -0.000212    |\n",
      "|    value_loss           | 0.265        |\n",
      "------------------------------------------\n",
      "-------------------------------------------\n",
      "| time/                   |               |\n",
      "|    fps                  | 46            |\n",
      "|    iterations           | 12            |\n",
      "|    time_elapsed         | 131           |\n",
      "|    total_timesteps      | 6144          |\n",
      "| train/                  |               |\n",
      "|    approx_kl            | 3.3981632e-06 |\n",
      "|    clip_fraction        | 0             |\n",
      "|    clip_range           | 0.2           |\n",
      "|    entropy_loss         | -1.95         |\n",
      "|    explained_variance   | 0.000403      |\n",
      "|    learning_rate        | 1e-06         |\n",
      "|    loss                 | 0.0835        |\n",
      "|    n_updates            | 110           |\n",
      "|    policy_gradient_loss | -4.03e-05     |\n",
      "|    value_loss           | 0.246         |\n",
      "-------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# Train the AI model, this is where the AI model starts to learn\n",
    "#can actually beat the level at 4M steps\n",
    "model.learn(total_timesteps=4000000, callback=callback)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<stable_baselines3.ppo.ppo.PPO object at 0x000002008031A950>\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"C:/Users/ithompson/ml_train/python scripts/models/mario_ppo/bestmodel\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "model = PPO.load('C:/Users/ithompson/ml_train/python scripts/models/mario_ppo/bestmodel')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "state = env.reset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ithompson\\rl\\Lib\\site-packages\\gym\\utils\\passive_env_checker.py:272: UserWarning: \u001b[33mWARN: No render modes was declared in the environment (env.metadata['render_modes'] is None or not defined), you may have trouble when calling `.render()`.\u001b[0m\n",
      "  logger.warn(\n",
      "c:\\Users\\ithompson\\rl\\Lib\\site-packages\\gym_super_mario_bros\\smb_env.py:148: RuntimeWarning: overflow encountered in scalar subtract\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[31], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m: \n\u001b[0;32m      6\u001b[0m     action, _ \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mpredict(state)\n\u001b[1;32m----> 7\u001b[0m     state, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      8\u001b[0m     env\u001b[38;5;241m.\u001b[39mrender()\n",
      "File \u001b[1;32mc:\\Users\\ithompson\\rl\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\base_vec_env.py:206\u001b[0m, in \u001b[0;36mVecEnv.step\u001b[1;34m(self, actions)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;124;03mStep the environments with the given action\u001b[39;00m\n\u001b[0;32m    201\u001b[0m \n\u001b[0;32m    202\u001b[0m \u001b[38;5;124;03m:param actions: the action\u001b[39;00m\n\u001b[0;32m    203\u001b[0m \u001b[38;5;124;03m:return: observation, reward, done, information\u001b[39;00m\n\u001b[0;32m    204\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    205\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_async(actions)\n\u001b[1;32m--> 206\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ithompson\\rl\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\vec_frame_stack.py:38\u001b[0m, in \u001b[0;36mVecFrameStack.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     32\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m     List[Dict[\u001b[38;5;28mstr\u001b[39m, Any]],\n\u001b[0;32m     37\u001b[0m ]:\n\u001b[1;32m---> 38\u001b[0m     observations, rewards, dones, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvenv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep_wait\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m     observations, infos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstacked_obs\u001b[38;5;241m.\u001b[39mupdate(observations, dones, infos)  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m observations, rewards, dones, infos\n",
      "File \u001b[1;32mc:\\Users\\ithompson\\rl\\Lib\\site-packages\\stable_baselines3\\common\\vec_env\\dummy_vec_env.py:58\u001b[0m, in \u001b[0;36mDummyVecEnv.step_wait\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     55\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep_wait\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m VecEnvStepReturn:\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m# Avoid circular imports\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m env_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_envs):\n\u001b[1;32m---> 58\u001b[0m         obs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_rews[env_idx], terminated, truncated, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_infos[env_idx] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menvs\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m     59\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43menv_idx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     61\u001b[0m         \u001b[38;5;66;03m# convert to SB3 VecEnv api\u001b[39;00m\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuf_dones[env_idx] \u001b[38;5;241m=\u001b[39m terminated \u001b[38;5;129;01mor\u001b[39;00m truncated\n",
      "File \u001b[1;32mc:\\Users\\ithompson\\rl\\Lib\\site-packages\\shimmy\\openai_gym_compatibility.py:117\u001b[0m, in \u001b[0;36mGymV26CompatibilityV0.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    108\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: ActType) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mtuple\u001b[39m[ObsType, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mdict\u001b[39m]:\n\u001b[0;32m    109\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment.\u001b[39;00m\n\u001b[0;32m    110\u001b[0m \n\u001b[0;32m    111\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    115\u001b[0m \u001b[38;5;124;03m        (observation, reward, terminated, truncated, info)\u001b[39;00m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 117\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgym_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ithompson\\rl\\Lib\\site-packages\\gym\\core.py:384\u001b[0m, in \u001b[0;36mObservationWrapper.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    382\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m    383\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns a modified observation using :meth:`self.observation` after calling :meth:`env.step`.\"\"\"\u001b[39;00m\n\u001b[1;32m--> 384\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    385\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobservation(observation), reward, terminated, truncated, info\n",
      "File \u001b[1;32mc:\\Users\\ithompson\\rl\\Lib\\site-packages\\nes_py\\wrappers\\joypad_space.py:74\u001b[0m, in \u001b[0;36mJoypadSpace.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     59\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;124;03mTake a step using the given action.\u001b[39;00m\n\u001b[0;32m     61\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     71\u001b[0m \n\u001b[0;32m     72\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     73\u001b[0m \u001b[38;5;66;03m# take the step and record the output\u001b[39;00m\n\u001b[1;32m---> 74\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_action_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ithompson\\rl\\Lib\\site-packages\\gym\\wrappers\\time_limit.py:50\u001b[0m, in \u001b[0;36mTimeLimit.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[0;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment and if the number of steps elapsed exceeds ``max_episode_steps`` then truncate.\u001b[39;00m\n\u001b[0;32m     41\u001b[0m \n\u001b[0;32m     42\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     48\u001b[0m \n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 50\u001b[0m     observation, reward, terminated, truncated, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_elapsed_steps \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_max_episode_steps:\n",
      "File \u001b[1;32mc:\\Users\\ithompson\\rl\\Lib\\site-packages\\gym\\wrappers\\order_enforcing.py:37\u001b[0m, in \u001b[0;36mOrderEnforcing.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_has_reset:\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m ResetNeeded(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot call env.step() before calling env.reset()\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 37\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ithompson\\rl\\Lib\\site-packages\\gym\\wrappers\\env_checker.py:39\u001b[0m, in \u001b[0;36mPassiveEnvChecker.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m env_step_passive_checker(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv, action)\n\u001b[0;32m     38\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m---> 39\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ithompson\\rl\\Lib\\site-packages\\gym\\wrappers\\compatibility.py:105\u001b[0m, in \u001b[0;36mEnvCompatibility.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[Any, \u001b[38;5;28mfloat\u001b[39m, \u001b[38;5;28mbool\u001b[39m, \u001b[38;5;28mbool\u001b[39m, Dict]:\n\u001b[0;32m     97\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Steps through the environment.\u001b[39;00m\n\u001b[0;32m     98\u001b[0m \n\u001b[0;32m     99\u001b[0m \u001b[38;5;124;03m    Args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    103\u001b[0m \u001b[38;5;124;03m        (observation, reward, terminated, truncated, info)\u001b[39;00m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 105\u001b[0m     obs, reward, done, info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    107\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhuman\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    108\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mrender()\n",
      "File \u001b[1;32mc:\\Users\\ithompson\\rl\\Lib\\site-packages\\nes_py\\nes_env.py:300\u001b[0m, in \u001b[0;36mNESEnv.step\u001b[1;34m(self, action)\u001b[0m\n\u001b[0;32m    298\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcontrollers[\u001b[38;5;241m0\u001b[39m][:] \u001b[38;5;241m=\u001b[39m action\n\u001b[0;32m    299\u001b[0m \u001b[38;5;66;03m# pass the action to the emulator as an unsigned byte\u001b[39;00m\n\u001b[1;32m--> 300\u001b[0m \u001b[43m_LIB\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mStep\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_env\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    301\u001b[0m \u001b[38;5;66;03m# get the reward for this step\u001b[39;00m\n\u001b[0;32m    302\u001b[0m reward \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mfloat\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_reward())\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Start the game =, test out the model\n",
    "state = env.reset()\n",
    "# Loop through the game\n",
    "while True: \n",
    "    \n",
    "    action, _ = model.predict(state)\n",
    "    state, reward, done, info = env.step(action)\n",
    "    env.render()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
